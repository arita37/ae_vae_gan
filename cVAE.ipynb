{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоэнкодеры в Keras\n",
    "\n",
    "# Часть 4: Conditional VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "* Часть 1: Введение\n",
    "* Часть 2: *Manifold learning* и скрытые (*latent*) переменные\n",
    "* Часть 3: Вариационные автоэнкодеры (*VAE*)\n",
    "* ** Часть 4: *Conditional VAE* **\n",
    "* Часть 5: *GAN* (Generative Adversarial Networks) и tensorflow\n",
    "* Часть 6: *VAE* + *GAN*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В прошлой части мы познакомились с ***вариационными автоэнкодерами (VAE)***, реализовали такой на *keras*, а так же поняли, как с его помощью генерировать изображения. Получившаяся модель, однако, обладала некоторыми недостатками:\n",
    "1. Не все цифры получилось хорошо закодировать в скрытом пространстве: некоторые цифры либо, вообще остсутствовали, либо были очень смазанными. В промежутках между областями, в которых были сконцентрированы варианты одной и той же цифры, находились вообще какие-то быссмысленные иероглифы.  \n",
    "    Что тут писать, вот так выглядели сгенерированные цифры:\n",
    "<img src=\"./figs4/manifold_vae.png\" width=\"400\"/>\n",
    "2. Сложно было генерировать картинку какой-то заданной цифры. Для этого надо было смотреть, в какую область латентного пространства попадали изображения конкретной цифры, и сэмплить уже откуда-то оттуда, а тем более было сложно генерировать цифру в каком-то заданном стиле.\n",
    "\n",
    "В этой части мы посмотрим как можно лишь очень слегка усложнив модель преодолеть обе эти проблемы, и заодно получим возможность генерировать картинки новых цифр в стиле другой цифры - это наверное самая интересная фича будущей модели. \n",
    "\n",
    "### Сначала подумаем о причинах 1-го недостатка:  \n",
    "Многообразия на которых лежат различные цифры могут быть далеко друг от друга в пространстве картинок. То есть сложно представить, как например непрерывно отобразить картинку цифры '5', в картинку цифры '7', при том, чтобы все промежуточные картинки можно было назвать правдоподобными. Таким образом, многообразие, около которого лежат цифры, вовсе не обязано быть линейно связным. Автоэнкодер же, в силу того что является композицией непрерывных функций, сам может отображать в код и обратно только непрерывно, особенно если это вариационный автоэнкодер. В нашем предыдущем примере все усложнялось еще и тем, что, автоэнкодер пытался искать двумерное многообразие.  \n",
    "В качестве иллюстрации вернемся к нашему искусственному примеру из 2-ой части, только сделаем определяющее многообразие несвязным:\n",
    "<img src=\"./figs4/disconnected_manifold.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь:\n",
    "* синие и зеленые точки - объекты выборки,\n",
    "* красная и желтая кривые - несвязанное определяющее многообразие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем теперь выучить определяющее многообразие с помощью обычного глубокого автоэнкодера.  \n",
    "Код: (скрыто)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Создание датасета\n",
    "x1 = np.linspace(-2.2, 2.2, 1000)\n",
    "fx = np.sin(x1)\n",
    "dots1 = np.vstack([x1, fx]).T\n",
    "\n",
    "t = np.linspace(0, 2*np.pi, num=1000)\n",
    "dots2 = 0.5*np.array([np.sin(t), np.cos(t)]).T + np.array([1.5, -0.5])[None, :]\n",
    "\n",
    "dots = np.vstack([dots1, dots2])\n",
    "noise = 0.06 * np.random.randn(*dots.shape)\n",
    "\n",
    "labels = np.array([0]*1000 + [1]*1000)\n",
    "noised = dots + noise\n",
    "\n",
    "\n",
    "# Визуализация\n",
    "colors = ['b']*1000 + ['g']*1000\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.xlim([-2.5, 2.5])\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.scatter(noised[:, 0], noised[:, 1], c=colors)\n",
    "plt.plot(dots1[:, 0], dots1[:, 1],  color=\"red\",    linewidth=4)\n",
    "plt.plot(dots2[:, 0], dots2[:, 1],  color=\"yellow\", linewidth=4)\n",
    "plt.grid(False)\n",
    "\n",
    "# Модель и обучение\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def deep_ae():\n",
    "    input_dots = Input((2,))\n",
    "    x = Dense(64, activation='elu')(input_dots)\n",
    "    x = Dense(64, activation='elu')(x)\n",
    "    code = Dense(1, activation='linear')(x)\n",
    "    x = Dense(64, activation='elu')(code)\n",
    "    x = Dense(64, activation='elu')(x)\n",
    "    out = Dense(2, activation='linear')(x)\n",
    "\n",
    "    ae = Model(input_dots, out)\n",
    "    return ae\n",
    "\n",
    "dae = deep_ae()\n",
    "dae.compile(Adam(0.001), 'mse')\n",
    "dae.fit(noised, noised, epochs=300, batch_size=30, verbose=2)\n",
    "\n",
    "# Результат\n",
    "predicted = dae.predict(noised)\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.xlim([-2.5, 2.5])\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.scatter(noised[:, 0], noised[:, 1], c=colors)\n",
    "plt.plot(dots1[:, 0], dots1[:, 1],  color=\"red\",    linewidth=4)\n",
    "plt.plot(dots2[:, 0], dots2[:, 1],  color=\"yellow\", linewidth=4)\n",
    "plt.scatter(predicted[:, 0], predicted[:, 1], c='white', s=50)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figs4/disconnected_manifold_dae.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* белая линия - многообразие в которое переходят синие и зеленые точки данных после автоэнкодера,\n",
    "то есть попытка автоэнкодера построить многообразие, определяющее больше всего вариации в данных\n",
    "\n",
    "Видно, что у простого автоэнкодера не получилось выучить форму несвязного многообразия. Вместо этого, он хитро продолжил одно в другое.\n",
    "\n",
    "Если же мы знаем лейблы данных, которые определяют на каком из частей несвязного многообразия лежат данные (как с цифрами), то мы можем просто *condition* автоэнкодер на этих лейблах. То есть просто дополнительно с данными, подавать на вход энкодеру и декодеру еще и лейблы данных. В таком случае источником разрывности в данных будет лейбл и это позволит автоэнкодеру выучить каждую часть линейно несвязного многообразия отдельно.\n",
    "\n",
    "Посмотрим на тот же самый пример, только теперь на вход и энкодеру, и декодеру будем передавать дополнительно еще и лейбл.\n",
    "\n",
    "Код (скрыто):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "\n",
    "def deep_cond_ae():\n",
    "    input_dots = Input((2,))\n",
    "    input_lbls = Input((1,))\n",
    "    full_input = concatenate([input_dots, input_lbls])\n",
    "    x = Dense(64, activation='elu')(full_input)\n",
    "    x = Dense(64, activation='elu')(x)\n",
    "    code = Dense(1, activation='linear')(x)\n",
    "\n",
    "    full_code = concatenate([code, input_lbls])\n",
    "    x = Dense(64, activation='elu')(full_code)\n",
    "    x = Dense(64, activation='elu')(x)\n",
    "    out = Dense(2, activation='linear')(x)\n",
    "\n",
    "    ae = Model([input_dots, input_lbls], out)\n",
    "    return ae\n",
    "\n",
    "cdae = deep_cond_ae()\n",
    "cdae.compile(Adam(0.001), 'mse')\n",
    "cdae.fit([noised, labels], noised, epochs=300, batch_size=30, verbose=2)\n",
    "\n",
    "\n",
    "predicted = cdae.predict([noised, labels])\n",
    "# Визуализация\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.xlim([-2.5, 2.5])\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.scatter(noised[:, 0], noised[:, 1], c=colors)\n",
    "plt.plot(dots1[:, 0], dots1[:, 1],  color=\"red\",    linewidth=4)\n",
    "plt.plot(dots2[:, 0], dots2[:, 1],  color=\"yellow\", linewidth=4)\n",
    "plt.scatter(predicted[:, 0], predicted[:, 1], c='white', s=50)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figs4/disconnected_manifold_cdae.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этот раз автоэнкодеру удалось выучить линейно несвязное определяющее многообразие."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если же теперь взять *VAE* как в предыдущей части, и подавать на вход еще и лейблы, то получится ***Conditional Variational Autoencoder (CVAE)***. \n",
    "\n",
    "С картинками цифр получается вот так:\n",
    "\n",
    "![](./figs4/cvae_diagram.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картинка выше из ***[2]***\n",
    "\n",
    "При этом основное уравнение *VAE* из прошлой части, становится просто *conditioned* на $Y$ ($Y$ при этом не обязан быть дискретным), то есть на лейбле.\n",
    "\n",
    "$$\n",
    "\\log P(X|Y;\\theta_2) - KL[Q(Z|X,Y;\\theta_1)||P(Z|X,Y;\\theta_2)] = E_{Z \\sim Q}[\\log P(X|Z,Y;\\theta_2)] - KL[Q(Z|X,Y;\\theta_1)||N(0,I)]\n",
    "$$\n",
    "\n",
    "$Q(Z|X,Y;\\theta_1)$ при этом мы опять сравниваем с $N(0,I)$, вынуждая автоэнкодер искать $Z$ независимо от $Y$. \n",
    "\n",
    "*CVAE* кодирует в $Z$ свойства входного сигнала общие для всех $Y$.\n",
    "\n",
    "## Перенос стиля\n",
    "(Комментарий: это не тоже самое, что перенос стиля в Prisme, там совсем другое)\n",
    "\n",
    "Теперь становится понятно, как создавать новые картинки в стиле заданной:\n",
    "1. обучаем *CVAE* на картинках с лейблами,\n",
    "2. кодируем стиль заданной картинки в $Z$,\n",
    "3. меняя лейблы $Y$ создаем из закодированного $Z$ новые картинки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Код на *Keras*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код практически идентичен коду из предыдущей части, за исключением, того что теперь в энкодер и декодер передается и лейбл цифры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# import seaborn as sns\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test .astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))\n",
    "\n",
    "y_train_cat = to_categorical(y_train).astype(np.float32)\n",
    "y_test_cat  = to_categorical(y_test).astype(np.float32)\n",
    "num_classes = y_test_cat.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "latent_dim = 8\n",
    "dropout_rate = 0.3\n",
    "start_lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense \n",
    "from keras.layers import BatchNormalization, Dropout, Flatten, Reshape, Lambda\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def create_cvae():\n",
    "    models = {}\n",
    "\n",
    "    # Добавим Dropout и BatchNormalization\n",
    "    def apply_bn_and_dropout(x):\n",
    "        return Dropout(dropout_rate)(BatchNormalization()(x))\n",
    "\n",
    "    # Энкодер\n",
    "    input_img = Input(shape=(28, 28, 1))\n",
    "    flatten_img = Flatten()(input_img)\n",
    "    input_lbl = Input(shape=(num_classes,), dtype='float32')\n",
    "\n",
    "    x = concatenate([flatten_img, input_lbl])\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = apply_bn_and_dropout(x)\n",
    "    # Предсказываем параметры распределений\n",
    "    # Вместо того, чтобы предсказывать стандартное отклонение, предсказываем логарифм вариации\n",
    "    z_mean = Dense(latent_dim)(x)\n",
    "    z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "    # Сэмплирование из Q с трюком репараметризации\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(batch_size, latent_dim), mean=0., stddev=1.0)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    l = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    models[\"encoder\"]  = Model([input_img, input_lbl], l, 'Encoder') \n",
    "    models[\"z_meaner\"] = Model([input_img, input_lbl], z_mean, 'Enc_z_mean')\n",
    "    models[\"z_lvarer\"] = Model([input_img, input_lbl], z_log_var, 'Enc_z_log_var')\n",
    "\n",
    "    # Декодер\n",
    "    z = Input(shape=(latent_dim, ))\n",
    "    input_lbl_d = Input(shape=(num_classes,), dtype='float32')\n",
    "    x = concatenate([z, input_lbl_d])\n",
    "    x = Dense(256)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = apply_bn_and_dropout(x)\n",
    "    x = Dense(28*28, activation='sigmoid')(x)\n",
    "    decoded = Reshape((28, 28, 1))(x)\n",
    "\n",
    "    models[\"decoder\"] = Model([z, input_lbl_d], decoded, name='Decoder')\n",
    "    models[\"cvae\"]    = Model([input_img, input_lbl, input_lbl_d], \n",
    "                              models[\"decoder\"]([models[\"encoder\"]([input_img, input_lbl]), input_lbl_d]), \n",
    "                              name=\"CVAE\")\n",
    "    models[\"style_t\"] = Model([input_img, input_lbl, input_lbl_d], \n",
    "                               models[\"decoder\"]([models[\"z_meaner\"]([input_img, input_lbl]), input_lbl_d]), \n",
    "                               name=\"style_transfer\")\n",
    "    \n",
    "    \n",
    "    def vae_loss(x, decoded):\n",
    "        x = K.reshape(x, shape=(batch_size, 28*28))\n",
    "        decoded = K.reshape(decoded, shape=(batch_size, 28*28))\n",
    "        xent_loss = 28*28*binary_crossentropy(x, decoded)\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "        return (xent_loss + kl_loss)/2/28/28\n",
    "\n",
    "    return models, vae_loss\n",
    "\n",
    "models, vae_loss = create_cvae()\n",
    "cvae = models[\"cvae\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "cvae.compile(optimizer=Adam(start_lr), loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digit_size = 28\n",
    "\n",
    "def plot_digits(*args, invert_colors=False):\n",
    "    args = [x.squeeze() for x in args]\n",
    "    n = min([x.shape[0] for x in args])\n",
    "    figure = np.zeros((digit_size * len(args), digit_size * n))\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(len(args)):\n",
    "            figure[j * digit_size: (j + 1) * digit_size,\n",
    "                   i * digit_size: (i + 1) * digit_size] = args[j][i].squeeze()\n",
    "\n",
    "    if invert_colors:\n",
    "        figure = 1-figure\n",
    "\n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.grid(False)\n",
    "    ax = plt.gca()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "n = 15 # Картинка с 15x15 цифр\n",
    "\n",
    "from scipy.stats import norm\n",
    "# Так как сэмплируем из N(0, I), то сетку узлов, в которых генерируем цифры берем из обратной функции распределения\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "\n",
    "def draw_manifold(generator, lbl, show=True):\n",
    "    # Рисование цифр из многообразия\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    input_lbl = np.zeros((1, 10))\n",
    "    input_lbl[0, lbl] = 1\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = np.zeros((1, latent_dim))\n",
    "            z_sample[:, :2] = np.array([[xi, yi]])\n",
    "\n",
    "            x_decoded = generator.predict([z_sample, input_lbl])\n",
    "            digit = x_decoded[0].squeeze()\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "    if show:\n",
    "        # Визуализация\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(figure, cmap='Greys_r')\n",
    "        plt.grid(False)\n",
    "        ax = plt.gca()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        plt.show()\n",
    "    return figure\n",
    "\n",
    "\n",
    "def draw_z_distr(z_predicted, lbl):\n",
    "    # Рисование рпспределения z\n",
    "    input_lbl = np.zeros((1, 10))\n",
    "    input_lbl[0, lbl] = 1\n",
    "    im = plt.scatter(z_predicted[:, 0], z_predicted[:, 1])\n",
    "    im.axes.set_xlim(-5, 5)\n",
    "    im.axes.set_ylim(-5, 5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from keras.callbacks import LambdaCallback, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# Массивы в которые будем сохранять результаты для последующей визуализации\n",
    "figs = [[] for x in range(num_classes)]\n",
    "latent_distrs = [[] for x in range(num_classes)]\n",
    "epochs = []\n",
    "\n",
    "# Эпохи в которые будем сохранять\n",
    "save_epochs = set(list((np.arange(0, 59)**1.701).astype(np.int)) + list(range(10)))\n",
    "\n",
    "# Отслеживать будем на вот этих цифрах\n",
    "imgs = x_test[:batch_size]\n",
    "imgs_lbls = y_test_cat[:batch_size]\n",
    "n_compare = 10\n",
    "\n",
    "# Модели\n",
    "generator      = models[\"decoder\"]\n",
    "encoder_mean   = models[\"z_meaner\"]\n",
    "\n",
    "\n",
    "# Функция, которую будем запускать после каждой эпохи\n",
    "def on_epoch_end(epoch, logs):\n",
    "    if epoch in save_epochs:\n",
    "        clear_output() # Не захламляем output\n",
    "\n",
    "        # Сравнение реальных и декодированных цифр\n",
    "        decoded = cvae.predict([imgs, imgs_lbls, imgs_lbls], batch_size=batch_size)\n",
    "        plot_digits(imgs[:n_compare], decoded[:n_compare])\n",
    "\n",
    "        # Рисование многообразия для рандомного y и распределения z|y\n",
    "        draw_lbl = np.random.randint(0, num_classes)\n",
    "        print(draw_lbl)\n",
    "        for lbl in range(num_classes):\n",
    "            figs[lbl].append(draw_manifold(generator, lbl, show=lbl==draw_lbl))\n",
    "            idxs = y_test == lbl\n",
    "            z_predicted = encoder_mean.predict([x_test[idxs], y_test_cat[idxs]], batch_size)\n",
    "            latent_distrs[lbl].append(z_predicted)\n",
    "            if lbl==draw_lbl:\n",
    "                draw_z_distr(z_predicted, lbl)\n",
    "        epochs.append(epoch)\n",
    "\n",
    "\n",
    "# Коллбэки\n",
    "pltfig = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "# lr_red = ReduceLROnPlateau(factor=0.1, patience=25)\n",
    "tb     = TensorBoard(log_dir='./logs')\n",
    "\n",
    "\n",
    "# Запуск обучения \n",
    "cvae.fit([x_train, y_train_cat, y_train_cat], x_train, shuffle=True, epochs=1000,\n",
    "         batch_size=batch_size,\n",
    "         validation_data=([x_test, y_test_cat, y_test_cat], x_test),\n",
    "         callbacks=[pltfig, tb],\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты\n",
    "(Извиняюсь, что местами белые цифры на черном фоне, а местами черные на белом)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переводит цифры этот автоэнкодер вот так:\n",
    "![](./figs4/map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерированные цифры каждого лейбла сэмплированные из $N(0|I)$\n",
    "<img src=\"./figs4/manifold_0.png\" width=\"400\"/>\n",
    "<img src=\"./figs4/manifold_1.png\" width=\"400\"/>\n",
    "<img src=\"./figs4/manifold_2.png\" width=\"400\"/>\n",
    "<img src=\"./figs4/manifold_3.png\" width=\"400\"/>\n",
    "<img src=\"./figs4/manifold_4.png\" width=\"400\"/>\n",
    "<img src=\"./figs4/manifold_5.png\" width=\"400\"/>\n",
    "<img src=\"./figs4/manifold_6.png\" width=\"400\"/>\n",
    "<img src=\"./figs4/manifold_7.png\" width=\"400\"/>\n",
    "<img src=\"./figs4/manifold_8.png\" width=\"400\"/>\n",
    "<img src=\"./figs4/manifold_9.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация цифр заданного лейбла из $Z$ и распределение $Z$ для каждого лейбла (тяжелые гифки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(скрыто)\n",
    "<img src=\"./figs4/manifold_0.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_0.gif\" width=\"500\"/> \n",
    "<img src=\"./figs4/manifold_1.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_1.gif\" width=\"500\"/> \n",
    "<img src=\"./figs4/manifold_2.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_2.gif\" width=\"500\"/> \n",
    "<img src=\"./figs4/manifold_3.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_3.gif\" width=\"500\"/> \n",
    "<img src=\"./figs4/manifold_4.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_4.gif\" width=\"500\"/> \n",
    "<img src=\"./figs4/manifold_5.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_5.gif\" width=\"500\"/> \n",
    "<img src=\"./figs4/manifold_6.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_6.gif\" width=\"500\"/> \n",
    "<img src=\"./figs4/manifold_7.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_7.gif\" width=\"500\"/> \n",
    "<img src=\"./figs4/manifold_8.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_8.gif\" width=\"500\"/> \n",
    "<img src=\"./figs4/manifold_9.gif\" width=\"500\"/> <img src=\"./figs4/z_distr_9.gif\" width=\"500\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перенос стиля этой моделью"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве источником стиля возьмем первые 10 нулей, и на основе их кода $Z$ создадим остальные цифры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код (скрыто):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_transfer(model, X, lbl_in, lbl_out):\n",
    "    rows = X.shape[0]\n",
    "    if isinstance(lbl_in, int):\n",
    "        lbl = lbl_in\n",
    "        lbl_in = np.zeros((rows, 10))\n",
    "        lbl_in[:, lbl] = 1\n",
    "    if isinstance(lbl_out, int):\n",
    "        lbl = lbl_out\n",
    "        lbl_out = np.zeros((rows, 10))\n",
    "        lbl_out[:, lbl] = 1\n",
    "    return model.predict([X, lbl_in, lbl_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "lbl = 7\n",
    "generated = []\n",
    "prot = x_train[y_train == lbl][:n]\n",
    "\n",
    "for i in range(num_classes):\n",
    "    generated.append(style_transfer(models[\"style_t\"], prot, lbl, i))\n",
    "\n",
    "generated[lbl] = prot\n",
    "plot_digits(*generated, invert_colors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"./figs4/style_transfer.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Стиль перенесен довольно удачно: сохранен наклон и толщина штриха.\n",
    "\n",
    "Больше свойств стиля можно было бы переносить просто увеличив размерность $Z$, это также сделало бы цифры менее размытыми.\n",
    "\n",
    "В следующей части посмотрим, как используя *генеративные состязающиеся сети (GAN)*, научить автоэнкодер генерировать изображения практически неотличимые от настоящих."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Код создания гифок "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "\n",
    "def make_2d_figs_gif(figs, epochs, c, fname, fig): \n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=1, clip=False)\n",
    "    im = plt.imshow(np.zeros((28,28)), cmap='Greys', norm=norm)\n",
    "    plt.grid(None)\n",
    "    plt.title(\"Label: {}\\nEpoch: {}\".format(c, epochs[0]))\n",
    "\n",
    "    def update(i):\n",
    "        im.set_array(figs[i])\n",
    "        im.axes.set_title(\"Label: {}\\nEpoch: {}\".format(c, epochs[i]))\n",
    "        im.axes.get_xaxis().set_visible(False)\n",
    "        im.axes.get_yaxis().set_visible(False)\n",
    "        return im\n",
    "    \n",
    "    anim = FuncAnimation(fig, update, frames=range(len(figs)), interval=100)\n",
    "    anim.save(fname, dpi=80, writer='imagemagick')\n",
    "\n",
    "def make_2d_scatter_gif(zs, epochs, c, fname, fig):\n",
    "    im = plt.scatter(zs[0][:, 0], zs[0][:, 1])\n",
    "    plt.title(\"Label: {}\\nEpoch: {}\".format(c, epochs[0]))\n",
    "\n",
    "    def update(i):\n",
    "        fig.clear()\n",
    "        im = plt.scatter(zs[i][:, 0], zs[i][:, 1])\n",
    "        im.axes.set_title(\"Label: {}\\nEpoch: {}\".format(c, epochs[i]))\n",
    "        im.axes.set_xlim(-5, 5)\n",
    "        im.axes.set_ylim(-5, 5)\n",
    "        return im\n",
    "\n",
    "    anim = FuncAnimation(fig, update, frames=range(len(zs)), interval=100)\n",
    "    anim.save(fname, dpi=80, writer='imagemagick')\n",
    "\n",
    "for lbl in range(num_classes):\n",
    "    make_2d_figs_gif(figs[lbl], epochs, lbl, \"./figs4/manifold_{}.gif\".format(lbl), plt.figure(figsize=(7,7)))\n",
    "    make_2d_scatter_gif(latent_distrs[lbl], epochs, lbl, \"./figs4/z_distr_{}.gif\".format(lbl), plt.figure(figsize=(7,7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки и литература"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретическая часть основана на статье:  \n",
    "[1] Tutorial on Variational Autoencoders, Carl Doersch, https://arxiv.org/abs/1606.05908  \n",
    "и фактически является ее кратким изложением\n",
    "\n",
    "Многие картинки взяты из блога Isaac Dykeman:  \n",
    "[2] Isaac Dykeman, http://ijdykeman.github.io/ml/2016/12/21/cvae.html  \n",
    "\n",
    "Подробнее прочитать про расстояние Кульбака-Лейблера на русском можно в   \n",
    "[3] http://www.machinelearning.ru/wiki/images/d/d0/BMMO11_6.pdf  \n",
    "\n",
    "Код частично основан на статье *Francois Chollet*:  \n",
    "[4] https://blog.keras.io/building-autoencoders-in-keras.html  \n",
    "\n",
    "Другие интересные ссылки:  \n",
    "http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html  \n",
    "http://kvfrans.com/variational-autoencoders-explained/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
