{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоэнкодеры в Keras\n",
    "# Часть 1: Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "* ** Часть 1: Введение **\n",
    "* Часть 2: *Manifold learning* и скрытые (*latent*) переменные\n",
    "* Часть 3: Вариационные автоэнкодеры (*VAE*)\n",
    "* Часть 4: *Conditional VAE*\n",
    "* Часть 5: *GAN* (Generative Adversarial Networks) и tensorflow\n",
    "* Часть 6: *VAE* + *GAN*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Автоэнкодеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Автоэнкодеры*** - это нейронные сети прямого распространения, которые восстанавливают входной сигнал на выходе. Внутри у них имеется скрытый слой, который представляет собой *код* описывающий модель. *Автоэнкодеры* конструируются таким образом, чтобы не иметь возможность точно скопировать вход на выходе. Обычно их ограничивают в размерности *кода* (он меньше, чем размерность сигнала) или штрафуют за активации в *коде*. Входной сигнал восстанавливается с ошибками из-за потерь при кодировании, но чтобы их минимизировать, сеть вынуждена учиться отбирать наиболее важные признаки.\n",
    "\n",
    "То есть *автоэнкодеры* состоят из двух частей: энкодера $g$ и декодера $f$. Энкодер переводит входной сигнал в его представление (*код*): $h = g(x)$ , а декодер, как не трудно догадаться, восстанавливает сигнал по его *коду*:  $x=f(h)$.\n",
    "\n",
    "Автоэнкодер изменяя $f$ и $g$ стремится выучить тождественную функцию $x = f(g(x))$ минимизируя какой-то функционал ошибки\n",
    "\n",
    "$$ L(x, f(g(x))). $$\n",
    "\n",
    "При этом семейства функций энкодера $g$ и декодера $f$ как-то ограничены, чтобы автоэнкодер был вынужден отбирать наиболее важные свойства сигнала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs1/ae_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сама по себе способность автоэнкодеров сжимать данные используется редко, так как обычно они работают хуже, чем вручную написанные алгоритмы для конкретных типов данных вроде звуков или изображений. А также для них критически важно, чтобы данные принадлежали той генеральной совокупности, на которой сеть обучалась. Обучив автоэнкодер на цифрах, его нельзя применять для кодирования чето-то другого (например, человеческих лиц).\n",
    "\n",
    "Однако автоэнкодеры можно использовать для предобучения, например, когда стоит задача классификации, а размеченных пар слишком мало. Или для понижения размерности в данных для последующей визуализации. Либо когда просто надо научиться различать полезные свойства входного сигнала.\n",
    "\n",
    "Более того некоторые их развития (о которых тоже будет написано далее), такие как вариационный автоэнкодер (*VAE*), а также его сочетание с состязающимися генеративным сетями (*GAN*) дают очень интересные результаты и находятся сейчас на переднем крае науки о генеративных моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Keras*** - это очень удобная высокоуровненая библиотека для глубокого обучения, работающая поверх *theano* или *tensorflow*. В ее основе лежат слои, соединяя которые между собой получаем модели. Созданные однажды модели и слои сохраняют в себе свои внутренние параметры, и потому, например, можно обучить слой в одной модели, а использовать его уже в другой, что очень удобно. \n",
    "\n",
    "Модели *keras* легко сохранять/загружать, процесс их обучения прост, но в то же время глубоко настраиваемый, они также свободно встраиваются в *tensorflow/theano* код (как операции над тензорами).\n",
    "\n",
    "В качестве некоторой аналогии можно сказать, что *tensorflow* - аналог *numpy*, а *keras* - аналог *scikit-learn*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве данных будем использовать датасет рукописных цифр ***MNIST***\n",
    "\n",
    "Загрузим его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test .astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сжимающий автоэнкодер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала создадим наиболее простой (сжимающий, undercomplete) автоэнкодер с *кодом* малой размерности из двух полносвязных слоев: енкодера и декодера.\n",
    "Так как интенсивность цвета нормировали на единицу, то активацию выходного слоя возьмем сигмоидой.\n",
    "\n",
    "Создадим отдельные модели для энкодера, декодера и целого автоэнкодера. Для этого создаются экземпляры слоев и применяются один за другим. В конце все объединяется в модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "\n",
    "def create_dense_ae():\n",
    "    # Размерность кодированного представления\n",
    "    encoding_dim = 49\n",
    "\n",
    "    # Энкодер\n",
    "    # Входной плейсхолдер\n",
    "    input_img = Input(shape=(28, 28, 1)) # 28, 28, 1 - размерности строк, столбцов, фильтров одной картинки, без батч-размерности\n",
    "    # Вспомогательный решейпинга слой\n",
    "    flat_img = Flatten()(input_img)\n",
    "    # Кодированное полносвязным слоем представление\n",
    "    encoded = Dense(encoding_dim, activation='relu')(flat_img)\n",
    "    \n",
    "    # Декодер\n",
    "    # Раскодированное другим полносвязным слоем изображение\n",
    "    input_encoded = Input(shape=(encoding_dim,))\n",
    "    flat_decoded = Dense(28*28, activation='sigmoid')(input_encoded)\n",
    "    decoded = Reshape((28, 28, 1))(flat_decoded)\n",
    "\n",
    "    # Модели, в конструктор первым аргументом передаются входные слои, а вторым выходные слои\n",
    "    # Другие модели можно так же использовать как и слои\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим и скомпилируем модель (под компиляцией в данном случае понимается построение графа вычислений *обратного распространения ошибки*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder, decoder, autoencoder = create_dense_ae()\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взглянем на число параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
    "_________________________________________________________________\n",
    "encoder (Model)              (None, 49)                38465     \n",
    "_________________________________________________________________\n",
    "decoder (Model)              (None, 28, 28, 1)         39200     \n",
    "=================================================================\n",
    "Total params: 77,665.0\n",
    "Trainable params: 77,665.0\n",
    "Non-trainable params: 0.0\n",
    "_________________________________________________________________\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим теперь наш автоэнкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "Epoch 46/50\n",
    "60000/60000 [==============================] - 3s - loss: 0.0785 - val_loss: 0.0777\n",
    "Epoch 47/50\n",
    "60000/60000 [==============================] - 2s - loss: 0.0784 - val_loss: 0.0777\n",
    "Epoch 48/50\n",
    "60000/60000 [==============================] - 3s - loss: 0.0784 - val_loss: 0.0777\n",
    "Epoch 49/50\n",
    "60000/60000 [==============================] - 2s - loss: 0.0784 - val_loss: 0.0777\n",
    "Epoch 50/50\n",
    "60000/60000 [==============================] - 3s - loss: 0.0784 - val_loss: 0.0777\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция отрисовки цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_digits(*args):\n",
    "    args = [x.squeeze() for x in args]\n",
    "    n = min([x.shape[0] for x in args])\n",
    "    \n",
    "    plt.figure(figsize=(2*n, 2*len(args)))\n",
    "    for j in range(n):\n",
    "        for i in range(len(args)):\n",
    "            ax = plt.subplot(len(args), n, i*n + j + 1)\n",
    "            plt.imshow(args[i][j])\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем несколько изображений и, ради интереса, взглянем на пример кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "imgs = x_test[:n]\n",
    "encoded_imgs = encoder.predict(imgs, batch_size=n)\n",
    "encoded_imgs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "array([  6.64665604,   7.53528595,   3.81508064,   4.66803837,\n",
    "         1.50886345,   5.41063929,   9.28293324,  10.79530716,\n",
    "         0.39599913,   4.20529413,   6.53982353,   5.64758158,\n",
    "         5.25313473,   1.37336707,   9.37590599,   6.00672245,\n",
    "         4.39552879,   5.39900637,   4.11449528,   7.490417  ,\n",
    "        10.89267063,   7.74325705,  13.35806847,   3.59005809,\n",
    "         9.75185394,   2.87570286,   3.64097357,   7.86691713,\n",
    "         5.93383646,   5.52847338,   3.45317888,   1.88125253,\n",
    "         7.471385  ,   7.29820824,  10.02830505,  10.5430584 ,\n",
    "         3.2561543 ,   8.24713707,   2.2687614 ,   6.60069561,\n",
    "         7.58116722,   4.48140812,   6.13670635,   2.9162209 ,\n",
    "         8.05503941,  10.78182602,   4.26916027,   5.17175484,   6.18108797], dtype=float32)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Декодируем эти коды и сравним с оригиналами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = decoder.predict(encoded_imgs, batch_size=n)\n",
    "\n",
    "plot_digits(imgs, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs1/ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глубокий автоэнкодер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Никто не мешает нам сделать такой же автоэнкодер, но с большим числом слоев. В таком случае он сможет вычлинять более сложные нелинейные закономерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_deep_dense_ae():\n",
    "    # Размерность кодированного представления\n",
    "    encoding_dim = 49\n",
    "\n",
    "    # Энкодер\n",
    "    input_img = Input(shape=(28, 28, 1))\n",
    "    flat_img = Flatten()(input_img)\n",
    "    x = Dense(encoding_dim*3, activation='relu')(flat_img)\n",
    "    x = Dense(encoding_dim*2, activation='relu')(x)\n",
    "    encoded = Dense(encoding_dim, activation='linear')(x)\n",
    "    \n",
    "    # Декодер\n",
    "    input_encoded = Input(shape=(encoding_dim,))\n",
    "    x = Dense(encoding_dim*2, activation='relu')(input_encoded)\n",
    "    x = Dense(encoding_dim*3, activation='relu')(x)\n",
    "    flat_decoded = Dense(28*28, activation='sigmoid')(x)\n",
    "    decoded = Reshape((28, 28, 1))(flat_decoded)\n",
    "    \n",
    "    # Модели\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder\n",
    "\n",
    "d_encoder, d_decoder, d_autoencoder = create_deep_dense_ae()\n",
    "d_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на *summary* нашей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
    "_________________________________________________________________\n",
    "encoder (Model)              (None, 49)                134750    \n",
    "_________________________________________________________________\n",
    "decoder (Model)              (None, 28, 28, 1)         135485    \n",
    "=================================================================\n",
    "Total params: 270,235.0\n",
    "Trainable params: 270,235.0\n",
    "Non-trainable params: 0.0\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число параметров выросло более чем в 3 раза, посмотрим справится ли новая модель лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_autoencoder.fit(x_train, x_train,\n",
    "                  epochs=100,\n",
    "                  batch_size=256,\n",
    "                  shuffle=True,\n",
    "                  validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "Epoch 96/100\n",
    "60000/60000 [==============================] - 3s - loss: 0.0722 - val_loss: 0.0724\n",
    "Epoch 97/100\n",
    "60000/60000 [==============================] - 3s - loss: 0.0722 - val_loss: 0.0719\n",
    "Epoch 98/100\n",
    "60000/60000 [==============================] - 3s - loss: 0.0721 - val_loss: 0.0722\n",
    "Epoch 99/100\n",
    "60000/60000 [==============================] - 3s - loss: 0.0721 - val_loss: 0.0720\n",
    "Epoch 100/100\n",
    "60000/60000 [==============================] - 3s - loss: 0.0721 - val_loss: 0.0720\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "imgs = x_test[:n]\n",
    "encoded_imgs = d_encoder.predict(imgs, batch_size=n)\n",
    "encoded_imgs[0]\n",
    "\n",
    "decoded_imgs = d_decoder.predict(encoded_imgs, batch_size=n)\n",
    "\n",
    "plot_digits(imgs, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs1/dae.png)\n",
    "Видим, что лосс насыщается на значительно меньшей величине, да и цифрки слегка более приятные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сверточный автоэнкодер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как мы работаем с картинками, в данных должна присутствовать некоторая пространственная инвариантность, попробуем этим воспользоваться: построим *сверточный автоэнкодер*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "\n",
    "def create_deep_conv_ae():\n",
    "    input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "    x = Conv2D(128, (7, 7), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    encoded = Conv2D(1, (7, 7), activation='relu', padding='same')(x)\n",
    "\n",
    "    # На этом моменте представление  (7, 7, 1) т.е. 49-размерное\n",
    "\n",
    "    input_encoded = Input(shape=(7, 7, 1))\n",
    "    x = Conv2D(32, (7, 7), activation='relu', padding='same')(input_encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(128, (2, 2), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (7, 7), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    # Модели\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder\n",
    "\n",
    "c_encoder, c_decoder, c_autoencoder = create_deep_conv_ae()\n",
    "c_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "c_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "input_5 (InputLayer)         (None, 28, 28, 1)         0         \n",
    "_________________________________________________________________\n",
    "encoder (Model)              (None, 7, 7, 1)           24385     \n",
    "_________________________________________________________________\n",
    "decoder (Model)              (None, 28, 28, 1)         24385     \n",
    "=================================================================\n",
    "Total params: 48,770.0\n",
    "Trainable params: 48,770.0\n",
    "Non-trainable params: 0.0\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_autoencoder.fit(x_train, x_train,\n",
    "                epochs=64,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "Epoch 60/64\n",
    "60000/60000 [==============================] - 24s - loss: 0.0698 - val_loss: 0.0695\n",
    "Epoch 61/64\n",
    "60000/60000 [==============================] - 24s - loss: 0.0699 - val_loss: 0.0705\n",
    "Epoch 62/64\n",
    "60000/60000 [==============================] - 24s - loss: 0.0699 - val_loss: 0.0694\n",
    "Epoch 63/64\n",
    "60000/60000 [==============================] - 24s - loss: 0.0698 - val_loss: 0.0691\n",
    "Epoch 64/64\n",
    "60000/60000 [==============================] - 24s - loss: 0.0697 - val_loss: 0.0693\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "imgs = x_test[:n]\n",
    "encoded_imgs = c_encoder.predict(imgs, batch_size=n)\n",
    "decoded_imgs = c_decoder.predict(encoded_imgs, batch_size=n)\n",
    "\n",
    "plot_digits(imgs, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](figs1/cae.png)\n",
    "Не смотря на то, что количество параметров у этой сети намного меньше чем у полносвязных сетей, функция ошибки насыщается на значительно меньшей величине."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Denoising* автоэнкодер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Автоэнкодеры можно обучить убирать шум из данных: для этого просто передаем на вход зашумленные данные и сравниваем на выходе с данными без шума:\n",
    "\n",
    "$$ L(x, f(g(\\hat x))), $$\n",
    "где $\\hat x$ - зашумленные данные."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В *Keras* можно оборачивать произвольные операции из нижележащего фреймворка в Lambda слой. Обращаться к операциям из *tensorflow* или *theano* можно через модуль *backend*\n",
    "\n",
    "Создадим модель которая будет зашумлять входное изображение, а избавлять от шума переобучим какой-либо из уже созданных автоэнкодеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Lambda\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "def create_denoising_model(autoencoder):\n",
    "    def add_noise(x):\n",
    "        noise_factor = 0.5\n",
    "        x = x + K.random_normal(x.get_shape(), 0.5, noise_factor)\n",
    "        x = K.clip(x, 0., 1.)\n",
    "        return x\n",
    "\n",
    "    input_img  = Input(batch_shape=(batch_size, 28, 28, 1))\n",
    "    noised_img = Lambda(add_noise)(input_img)\n",
    "\n",
    "    noiser = Model(input_img, noised_img, name=\"noiser\")\n",
    "    denoiser_model = Model(input_img, autoencoder(noiser(input_img)), name=\"denoiser\")\n",
    "    return noiser, denoiser_model\n",
    "\n",
    "\n",
    "noiser, denoiser_model = create_denoising_model(autoencoder)\n",
    "denoiser_model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser_model.fit(x_train, x_train,\n",
    "                   epochs=200,\n",
    "                   batch_size=batch_size,\n",
    "                   shuffle=True,\n",
    "                   validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "imgs = x_test[:batch_size]\n",
    "noised_imgs = noiser.predict(imgs, batch_size=batch_size)\n",
    "encoded_imgs = encoder.predict(noised_imgs[:n],  batch_size=n)\n",
    "decoded_imgs = decoder.predict(encoded_imgs[:n], batch_size=n)\n",
    "\n",
    "plot_digits(imgs[:n], noised_imgs, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs1/denoiser.png)\n",
    "Цифры на зашумленных изображениях с трудом проглядываются, однако *denoising autoencoder* неплохо убрал шум и цифры стали вполне читаемыми"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разреженный (*Sparse*) автоэнкодер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разреженный автоэнкодер - это просто автоэнкодер, у которого в функцию потерь добавлен штраф за величины значений в *коде*, то есть автоэнкодер стремится минимизировать такую функцию ошибки:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ L(x, f(g(x))) + \\Omega(h), $$\n",
    "где $h = g(x)$ - код,\n",
    "\n",
    "$\\Omega(h)$ - обычный регуляризатор (например L1):\n",
    "$$\\Omega(h) = \\lambda * |h|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разреженный автоэнкодер не обязательно сужается к центру. Его *код* может иметь и большую размерность, чем входной сигнал. Обучаясь приближать тождественную функцию $x = f(g(x))$ он учится в *коде* выделять полезные свойства сигнала. Из-за регуляризатора даже расширяющийся к центру разреженный автоэнкодер не может выучить тождественную функцию напрямую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import L1L2\n",
    "\n",
    "def create_sparse_ae():\n",
    "    encoding_dim = 16\n",
    "    lambda_l1 = 0.00001\n",
    "    \n",
    "    # Энкодер\n",
    "    input_img = Input(shape=(28, 28, 1))\n",
    "    flat_img = Flatten()(input_img)\n",
    "    x = Dense(encoding_dim*3, activation='relu')(flat_img)\n",
    "    x = Dense(encoding_dim*2, activation='relu')(x)\n",
    "    encoded = Dense(encoding_dim, activation='linear', activity_regularizer=L1L2(lambda_l1))(x)\n",
    "    \n",
    "    # Декодер\n",
    "    input_encoded = Input(shape=(encoding_dim,))\n",
    "    x = Dense(encoding_dim*2, activation='relu')(input_encoded)\n",
    "    x = Dense(encoding_dim*3, activation='relu')(x)\n",
    "    flat_decoded = Dense(28*28, activation='sigmoid')(x)\n",
    "    decoded = Reshape((28, 28, 1))(flat_decoded)\n",
    "    \n",
    "    # Модели\n",
    "    encoder = Model(input_img, encoded, name=\"encoder\")\n",
    "    decoder = Model(input_encoded, decoded, name=\"decoder\")\n",
    "    autoencoder = Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "    return encoder, decoder, autoencoder\n",
    "\n",
    "s_encoder, s_decoder, s_autoencoder = create_sparse_ae()\n",
    "s_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_autoencoder.fit(x_train, x_train,\n",
    "                epochs=400,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взглянем на коды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "imgs = x_test[:n]\n",
    "encoded_imgs = s_encoder.predict(imgs, batch_size=n)\n",
    "encoded_imgs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "array([  7.13531828,  -0.61532277,  -5.95510817,  12.0058918 ,\n",
    "        -1.29253936,  -8.56000137,  -7.48944521,  -0.05415952,\n",
    "        -2.81205249,  -8.4289856 ,  -0.67815018, -11.19531345,\n",
    "        -3.4353714 ,   3.18580866,  -0.21041733,   4.13229799], dtype=float32)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = s_decoder.predict(encoded_imgs, batch_size=n)\n",
    "\n",
    "plot_digits(imgs, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs1/sae.png)\n",
    "Посмотрим, можно ли как-то интерпретировать размерности в кодах.  \n",
    "Возьмем среднее из всех кодов, а потом поочереди каждую размерность в среднем коде заменим на максимальное ее значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = x_test\n",
    "encoded_imgs = s_encoder.predict(imgs, batch_size=16)\n",
    "codes = np.vstack([encoded_imgs.mean(axis=0)]*10)\n",
    "np.fill_diagonal(codes, encoded_imgs.max(axis=0))\n",
    "\n",
    "decoded_features = s_decoder.predict(codes, batch_size=16)\n",
    "plot_digits(decoded_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs1/sae_feat.png)\n",
    "Какие-то черты проглядываются, но ничего толкового тут не видно.\n",
    "Значения в кодах по одиночке никакого очевидного смысла не несут, лишь хитрое взаимодействие между значениями, происходящее в слоях декодера, позволяет ему по коду восстановить входной сигнал. \n",
    "\n",
    "Можно ли из кодов генерировать объекты по собственному желанию?\n",
    "\n",
    "Для того, чтобы ответить на этот вопрос, следует лучше изучить, что такое коды, и как их можно интепретировать. Про это в следующей части."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки и литература"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот пост основан на собственной интерпретации первой части поста создателя *Keras* *Francois Chollet* про автоэнкодеры в Keras:  \n",
    "https://blog.keras.io/building-autoencoders-in-keras.html  \n",
    "\n",
    "А так же главы про автоэнкодеры в *Deep Learning Book*:  \n",
    "http://www.deeplearningbook.org/contents/autoencoders.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
