{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Автоэнкодеры в Keras\n",
    "\n",
    "# Часть 5: GAN и tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Содержание\n",
    "\n",
    "* Часть 1: Введение\n",
    "* Часть 2: *Manifold learning* и скрытые (latent) переменные\n",
    "* Часть 3: Вариационные автоэнкодеры (*VAE*)\n",
    "* Часть 4: *Conditional VAE*\n",
    "* **Часть 5: *GAN* и tensorflow**\n",
    "* Часть 6: *VAE* + *GAN*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При всех преймуществах вариационных автоэнкодеров ***VAE***, которыми мы занимались в предыдущих постах, они обладают одним существенным недостатком: из-за плохого способа сравнения оригинальных и восстановленных объектов, сгенерированные ими объекты хоть и похожи на объекты из обучающей выборки, но легко от них отличимы (пример, размыты). \n",
    "\n",
    "Этот недостаток в куда меньшей степени проявляется у другого подхода, а именно у *генеративных состязающихся сетей* - ***GAN***'ов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формально *GAN'ы* конечно не относятся к автоэнкодерам, однако между ними и вариационными автоэнкодерами есть сходства, они также пригодятся для следующей части. Так что не будет лишним с ними тоже познакомиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коротко о *GAN*\n",
    "\n",
    "***GAN***'ы впервые были предложены в статье ***[1, Generative Adversarial Nets, Goodfellow et al, 2014]***\n",
    "и сейчас очень активно исследуются. Наиболее state-of-the-art генеративные модели так или иначе используют *adversarial*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***GAN***'ы состоят из 2 нейронных сетей: \n",
    "- 1-ая - генератор сэмплит случайные числа из какого-то заданного распределения $P(Z)$, например $N(0,I)$ и генерируют из них объекты $X_p = G(Z; \\theta_g)$, которые идут на вход второй сети,\n",
    "- 2-ая - дискриминатор получает на вход объекты из выборки $X_s$ и созданные генератором $X_p$, и учится предсказывать вероятность того, что конкретный объект реальный, выдавая скаляр $D(X; \\theta_d)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схема ***GAN***:\n",
    "![](figs5/GAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При этом генератор тренируется создавать объекты, который дискриминатор не отличит от реальных.  \n",
    "\n",
    "----\n",
    "**Рассмотрим процесс обучения *GAN*.**  \n",
    "\n",
    "Генератор и дискриминатор обучаются отдельно, но в рамках одной сети.  \n",
    "\n",
    "Делаем k шагов обучения дискриминатора: за шаг обучения дискриминатора параметры $\\theta_d$ обновляются в сторону уменьшения кросс-энтропии:\n",
    "\n",
    "$$\n",
    "\\theta_d = \\theta_d - ∇_{\\theta_d} \\left(\\log(D(X_s)) + \\log(1 - D(G(Z))) \\right)\n",
    "$$\n",
    "\n",
    "Далее шаг обучения генератора: обновляем параметры генератора $\\theta_g$ в сторону увеличения логарифма вероятности дискриминатору присвоить сгенерированному объекту лейбл реального.\n",
    "\n",
    "$$\n",
    "\\theta_g = \\theta_g + ∇_{\\theta_g} \\log(1 - D(G(Z)))\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схема обучения:\n",
    "![](figs5/GAN_bp_dis_gen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На левой картинке шаг обучения дискриминатора: градиент (красные стрелки) протекает от лосса только до дискриминатора, где обновляются $\\theta_d$ (зеленые) в сторону уменьшения лосса. На правой картинке градиент от правой части лосса (ошибка идентификации сгенерированного объекта) протекает до генератора, при этом обновляются только веса генератора $\\theta_g$ (зеленые) в сторону **увеличения** вероятности дискриминатора ошибиться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача, которую решает *GAN* формулируется так:\n",
    "\n",
    "$$\n",
    "\\min_G \\max_D \\mathbb{E}_{X \\sim P}[ \\log(D(X))] + \\mathbb{E}_{Z \\sim P_z}[ \\log(1 - D(G(Z)))]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ***[1]*** показывается, что при достаточной мощности обеих сетей у данной задачи есть оптимум, в котором генератор научился генерировать распределение $P_g(X)$ совпадающее с $P(X)$, а везде на $X$ дискриминатор выдает вероятность $1/2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs5/GAN_learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иллюстрация из ***[1]***  \n",
    "\n",
    "Обозначения:\n",
    "- черная точечная кривая - настоящее распределение $P(X)$, \n",
    "- зеленая - распределение генератора $P_g(X)$, \n",
    "- синяя - распределение вероятности $D(X;\\theta_d)$ дискриминатора предсказать класс реального объекта,\n",
    "- нижняя и верхняя прямые - множество всех $Z$ и множество всех $X$, стрелочки олицетворяют отображение $G(Z;\\theta_g)$.\n",
    "\n",
    "На картинке:\n",
    "- (a) $P(X)$ и $P_g(X)$ довольно разные, но дискриминатор не уверено отличает одно от другого, \n",
    "- (b) дискриминатор после k шагов обучения уже отличает их увереннее, \n",
    "- (c) это позволяет генератору $G$ руководствуясь хорошим градиентом дискриминатора $D$ на границе двух распределений подвинуть $P_g(X)$ ближе к $P(X)$,\n",
    "- (d) в результате многих повторений шагов (а), (b), (c) $P_g$ совпало с $P$ и дискриминатор более не способен отличать одно от другого: $D(X) = 1/2$. Точка оптимума достигнута."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точно как в прошлой части мы сделали *Conditional VAE* просто передавая в энкодер и декодер лейбл цифры, здесь мы будем передавать его в генератор и дискриминатор ***[2]***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs5/CGAN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Код\n",
    "В отличие от предыдущих частей, где получалось обходиться одним *keras'ом*, здесь с этим возникает проблема. А именно, нужно в одной и той же сети по-очереди обновлять либо только параметры генератора, либо только дискриминатора. Если исхитриться, то можно сделать это и чисто в *keras'е*, но по мне проще и полезнее подключить сюда и *tensorflow*.\n",
    "В блоге *keras'а* есть небольшой [туториал](https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html) ***[3]***  как это делать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Благо *keras* легко сочетается с *tensorflow* - не даром он попал в *tensorflow.contrib*.\n",
    "\n",
    "Начнем с импортирования нужных модулей и загрузки датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.layers import Dropout, BatchNormalization, Reshape, Flatten, RepeatVector\n",
    "from keras.layers import Lambda, Dense, Input, Conv2D, MaxPool2D, UpSampling2D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test  = x_test .astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test  = np.reshape(x_test,  (len(x_test),  28, 28, 1))\n",
    "\n",
    "y_train_cat = to_categorical(y_train).astype(np.float32)\n",
    "y_test_cat  = to_categorical(y_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы в *keras* и *tensorflow* одновременно, надо зарегистрировать *tensorflow* сессию в *keras*, это нужно для того, чтобы *keras* создавал все внутренние переменные в рамках используемой сессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим основные глобальные константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "batch_shape = (batch_size, 28, 28, 1)\n",
    "latent_dim = 2\n",
    "num_classes = 10\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучать модель мы теперь будем не с помощью метода *.fit*, а напрямую из *tensorflow*, поэтому напишем итератор, возвращающий очередной батч"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_batch(x, y):\n",
    "    n_batches = x.shape[0] // batch_size\n",
    "    while(True):\n",
    "        for i in range(n_batches):\n",
    "            yield x[batch_size*i: batch_size*(i+1)], y[batch_size*i: batch_size*(i+1)]\n",
    "        idxs = np.random.permutation(y.shape[0])\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "\n",
    "\n",
    "train_batches_it = gen_batch(x_train, y_train_cat)\n",
    "test_batches_it  = gen_batch(x_test,  y_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оборачиваем *placeholder*'ы для картинок, лейблов и скрытых переменных во входящие слои для *keras* моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_ = tf.placeholder(tf.float32, shape=(None, 28, 28, 1),   name='image')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, num_classes), name='labels')\n",
    "z_ = tf.placeholder(tf.float32, shape=(None, latent_dim),  name='z')\n",
    "\n",
    "img = Input(tensor=x_)\n",
    "lbl = Input(tensor=y_)\n",
    "z   = Input(tensor=z_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовывать будем сразу ***CGAN***, так как он лишь минимально отличается от обычного.  \n",
    "Напишем модель генератора. *Keras* работает со *scope'ами*, а нам нужно разделить генератор и дикриминатор, чтобы потом обучать их по-отдельности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('generator'):\n",
    "    x = concatenate([z, lbl])\n",
    "    x = Dense(7*7*64, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Reshape((7, 7, 64))(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "    generated = Conv2D(1, kernel_size=(5, 5), activation='sigmoid', padding='same')(x)\n",
    "generator = Model([z, lbl], generated, name='generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, модель дискриминатора. Здесь нам нужно добавить ко входящему изображению еще лейбл цифры. Для этого после применения первого сверточного слоя, добавим к фильтрам лейблы. Сперва функция, которая это делает, потом модель дискриминатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_units_to_conv2d(conv2, units):\n",
    "    dim1 = int(conv2.shape[1])\n",
    "    dim2 = int(conv2.shape[2])\n",
    "    dimc = int(units.shape[1])\n",
    "    repeat_n = dim1*dim2\n",
    "    units_repeat = RepeatVector(repeat_n)(lbl)\n",
    "    units_repeat = Reshape((dim1, dim2, dimc))(units_repeat)\n",
    "    return concatenate([conv2, units_repeat])\n",
    "\n",
    "\n",
    "with tf.variable_scope('discrim'):\n",
    "    x = Conv2D(128, kernel_size=(7, 7), strides=(2, 2), padding='same')(img)\n",
    "    x = add_units_to_conv2d(x, lbl)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = MaxPool2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    l = Conv2D(128, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = LeakyReLU()(l)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    h = Flatten()(x)\n",
    "    d = Dense(1, activation='sigmoid')(h)\n",
    "discrim = Model([img, lbl], d, name='Discriminator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определив модели, мы можем применять их напрямую к *placeholder'ам* как обычные *tensorflow* операции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_z = generator([z, lbl])\n",
    "\n",
    "discr_img   = discrim([img, lbl])\n",
    "discr_gen_z = discrim([generated_z, lbl])\n",
    "\n",
    "gan_model = Model([z, lbl], discr_gen_z, name='GAN')\n",
    "gan   = gan_model([z, lbl])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь лосс ошибки определения реального изображения, и лосс сгенерированного, а также на их основе лоссы генератора и дискриминатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_dis_img   = tf.reduce_mean(-tf.log(discr_img + 1e-10))\n",
    "log_dis_gen_z = tf.reduce_mean(-tf.log(1. - discr_gen_z + 1e-10))\n",
    "\n",
    "L_gen = -log_dis_gen_z\n",
    "L_dis = 0.5*(log_dis_gen_z + log_dis_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно в *tensorflow*, передавая в оптимизатор лосс, он будет пытаться минимизировать сразу все переменные, от которых он зависит. Нам сейчас этого не надо: обучая генератор, ошибка не должна трогать дискриминатор, хотя должна сквозь него течь и наоборот.\n",
    "\n",
    "Для этого дополнительно в оптимизатор надо передать список переменных которые он будет оптимизировать. Достанем эти переменные из нужных *scope'ов* с помощью *tf.get_collection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer_gen = tf.train.RMSPropOptimizer(0.0003)\n",
    "optimizer_dis = tf.train.RMSPropOptimizer(0.001)\n",
    "\n",
    "# Переменные генератора и дискриминаторы (отдельно) для оптимизаторов\n",
    "generator_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generator\")\n",
    "discrim_vars   = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discrim\")\n",
    "\n",
    "step_gen = optimizer_gen.minimize(L_gen, var_list=generator_vars)\n",
    "step_dis = optimizer_dis.minimize(L_dis, var_list=discrim_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Инициализируем переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отдельно напишем функции, которые будем вызывать для обучения генератора и дискриминатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Шаг обучения генератора\n",
    "def step(image, label, zp):\n",
    "    l_dis, _ = sess.run([L_dis, step_gen], feed_dict={z:zp, lbl:label, img:image, K.learning_phase():1})\n",
    "    return l_dis\n",
    "\n",
    "# Шаг обучения дискриминатора\n",
    "def step_d(image, label, zp):\n",
    "    l_dis, _ = sess.run([L_dis, step_dis], feed_dict={z:zp, lbl:label, img:image, K.learning_phase():1})\n",
    "    return l_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код сохранения и визуализации картинок (скрыто)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Массивы в которые будем сохранять результаты, для последующей визуализации\n",
    "figs = [[] for x in range(num_classes)]\n",
    "periods = []\n",
    "\n",
    "save_periods = list(range(100)) + list(range(100, 1000, 10))\n",
    "\n",
    "n = 15 # Картинка с 15x15 цифр\n",
    "from scipy.stats import norm\n",
    "# Так как сэмплируем из N(0, I), то сетку узлов, в которых генерируем цифры берем из обратной функции распределения\n",
    "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
    "def draw_manifold(label, show=True):\n",
    "    # Рисование цифр из многообразия\n",
    "    figure = np.zeros((28 * n, 28 * n))\n",
    "    input_lbl = np.zeros((1, 10))\n",
    "    input_lbl[0, label] = 1.\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = np.zeros((1, latent_dim))\n",
    "            z_sample[:, :2] = np.array([[xi, yi]])\n",
    "\n",
    "            x_generated = sess.run(generated_z, feed_dict={z:z_sample, lbl:input_lbl, K.learning_phase():0})\n",
    "            digit = x_generated[0].squeeze()\n",
    "            figure[i * 28: (i + 1) * 28,\n",
    "                   j * 28: (j + 1) * 28] = digit\n",
    "    if show:\n",
    "        # Визуализация\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(figure, cmap='Greys')\n",
    "        plt.grid(False)\n",
    "        ax = plt.gca()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        plt.show()\n",
    "    return figure\n",
    "\n",
    "\n",
    "n_compare = 10\n",
    "def on_n_period(period):\n",
    "    clear_output() # Не захламляем output\n",
    "\n",
    "    # Рисование многообразия для рандомного y\n",
    "    draw_lbl = np.random.randint(0, num_classes)    \n",
    "    print(draw_lbl)\n",
    "    for label in range(num_classes):\n",
    "        figs[label].append(draw_manifold(label, show=label==draw_lbl))\n",
    "\n",
    "    periods.append(period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим теперь наш *CGAN*.  \n",
    "Для *GAN'ов* очень критично, чтобы не одна сеть сильно не побеждала (иначе градиент слишком близок к 0 и обучение останавливается). Поэтому здесь добавлены внутренние циклы как для дискриминатора, так и для генератора, и выход из них, когда одна сеть почти догоняет другую. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches_per_period = 20 # Как часто сохранять картинки\n",
    "k_step = 10 # Максимальное количество шагов, которые могут делать декодер или энкодер\n",
    "\n",
    "for i in range(5000):\n",
    "    print('.', end='')\n",
    "    # Достанем новый батч\n",
    "    b0, b1 = next(train_batches_it)\n",
    "    zp = np.random.randn(batch_size, latent_dim)\n",
    "    # Шаги обучения дискриминатора\n",
    "    for j in range(k_step):\n",
    "        l_d = step_d(b0, b1, zp)\n",
    "        b0, b1 = next(train_batches_it)\n",
    "        zp = np.random.randn(batch_size, latent_dim)\n",
    "        if l_d < 1.0:\n",
    "            break\n",
    "\n",
    "    # Шаги обучения генератора\n",
    "    for j in range(k_step):\n",
    "        l_d = step(b0, b1, zp)\n",
    "        if l_d > 0.4:\n",
    "            break\n",
    "        b0, b1 = next(train_batches_it)\n",
    "        zp = np.random.randn(batch_size, latent_dim)\n",
    "\n",
    "    # Периодическое рисование результата\n",
    "    if not i % batches_per_period:\n",
    "        period = i // batches_per_period\n",
    "        if period in save_periods:\n",
    "            on_n_period(period)\n",
    "        print(l_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код рисования гифок: (скрыто)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "\n",
    "def make_2d_figs_gif(figs, periods, c, fname, fig, batches_per_period): \n",
    "    norm = matplotlib.colors.Normalize(vmin=0, vmax=1, clip=False)\n",
    "    im = plt.imshow(np.zeros((28,28)), cmap='Greys', norm=norm)\n",
    "    plt.grid(None)\n",
    "    plt.title(\"Label: {}\\nBatch: {}\".format(c, 0))\n",
    "\n",
    "    def update(i):\n",
    "        im.set_array(figs[i])\n",
    "        im.axes.set_title(\"Label: {}\\nBatch: {}\".format(c, periods[i]*batches_per_period))\n",
    "        im.axes.get_xaxis().set_visible(False)\n",
    "        im.axes.get_yaxis().set_visible(False)\n",
    "        return im\n",
    "    \n",
    "    anim = FuncAnimation(fig, update, frames=range(len(figs)), interval=100)\n",
    "    anim.save(fname, dpi=80, writer='imagemagick')\n",
    "\n",
    "for label in range(num_classes):\n",
    "    make_2d_figs_gif(figs[label], periods, label, \"./figs4_5/manifold_{}.gif\".format(label), plt.figure(figsize=(10,10)), batches_per_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Результаты:\n",
    "\n",
    "### GAN\n",
    "Многообразие цифр для обычного *GAN* (без передачи лейблов)\n",
    "<img src=\"./figs5/GAN_manifold.png\" width=\"600\"/>\n",
    "Стоит отметить, что цифры получаются лучше, чем в *VAE* (без лейблов)  \n",
    "Гифка обучения: (скрыто)\n",
    "<img src=\"./figs5/manifold_all.gif\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### CGAN\n",
    "Многообразия цифр для каждого лейбла\n",
    "<img src=\"./figs5/manifold_0.png\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_1.png\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_2.png\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_3.png\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_4.png\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_5.png\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_6.png\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_7.png\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_8.png\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_9.png\" width=\"600\"/>\n",
    "\n",
    "Гифки обучения: (скрыто)\n",
    "<img src=\"./figs5/manifold_0.gif\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_1.gif\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_2.gif\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_3.gif\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_4.gif\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_5.gif\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_6.gif\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_7.gif\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_8.gif\" width=\"600\"/>\n",
    "<img src=\"./figs5/manifold_9.gif\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки и литература\n",
    "\n",
    "Оригинальная статья:  \n",
    "[1] Generative Adversarial Nets, Goodfellow et al, 2014, https://arxiv.org/abs/1406.2661\n",
    "\n",
    "Conditional GANs:  \n",
    "[2] Conditional Generative Adversarial Nets, Mirza, Osindero, 2014, https://arxiv.org/abs/1411.1784\n",
    "\n",
    "Туториал про использование *keras* вместе с *tensorflow*:  \n",
    "[3] https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
